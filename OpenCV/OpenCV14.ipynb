{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. 가장자리 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/wheat.jpg\", cv2.IMREAD_REDUCED_COLOR_2)\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sobel = cv2.Sobel(gray, cv2.CV_8U, 1, 0, 3)\n",
    "laplacian = cv2.Laplacian(gray, cv2.CV_8U, ksize=3)\n",
    "canny = cv2.Canny(src, 100, 255)\n",
    "\n",
    "cv2.imshow(\"sobel\", sobel)\n",
    "cv2.imshow(\"laplacian\", laplacian)\n",
    "cv2.imshow(\"canny\", canny)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel 함수 : 인접한 픽셀들의 차이로 기울기(Gradient)의 크기를 구함\n",
    "# dst = cv2.Sobel(image, ddepth, dx, dy, ksize, scale, delta, borderType)\n",
    "\n",
    "# ddepth(출력 이미지 정밀도) : 반환되는 결과 이미지의 정밀도 설정\n",
    "# dx(X 방향 미분 차수) : 이미지에서 X 방향으로 미분할 차수를 설정\n",
    "# dy(Y 방향 미분 차수) : 이미지에서 Y 방향으로 미분할 차수를 설정\n",
    "# ksize(커널 크기) : 소벨 마스크의 크기를 설정. 1, 3, 5, 7 등의 홀수 값을 사용, 최대 31까지 설정 가능\n",
    "# scale(비율), delta(오프셋) : 출력 이미지를 반환하기 전에 적용, 주로 시각적으로 확인하기 위해 사용\n",
    "# borderType(픽셀 외삽법) : 이미지 가장자리 부분의 처리 방식을 설정\n",
    "\n",
    "# dx+dy>=1이어야 하며 0이면 해당 방향으로 미분하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian 함수 : 2차 미분의 형태로 가장자리가 밝은 부분에서 발생한 것인지, 어두운 부분에서 발생한 것인지 판별\n",
    "# dst = cv2.laplacian(image, ddepth, ksize, scale, delta, borderType)\n",
    "\n",
    "# ddepth(출력 이미지 정밀도) : 반환되는 결과 이미지의 정밀도를 설정\n",
    "# ksize(커널 크기) : 라플라시안 필터의 크기를 설정. 커널의 값이 1일 경우, 중심값이 -4인 3 x 3 Aperture Size를 사용\n",
    "# scale(비율), delta(오프셋) : 출력 이미지를 반환하기 전에 적용, 주로 시각적으로 확인하기 위해 사용\n",
    "# borderType(픽셀 외삽법) : 이미지 가장자리 부분의 처리 방식을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny 함수\n",
    "# - 라플라스 필터 방식을 개선. x와 y에 대해 1차 미분을 계산한 다음, 네 방향으로 미분\n",
    "# - 네 방향으로 미분한 결과로 극댓값을 갖는 지점들이 가장자리\n",
    "# - 앞서 설명한 가장자리 검출기보다 성능이 월등히 좋으며 노이즈에 민감하지 않아 강한 가장자리를 검출하는 데 목적을 둔 알고리즘\n",
    "\n",
    "# dst = cv2.Canny(image, threshold1, threshold2, apertureSize, L2gradient)\n",
    "\n",
    "# threshold1(하위 임곗값), threshold2(상위 임곗값) : 픽셀이 갖는 최솟값과 최댓값을 설정해 검출을 진행\n",
    "# 픽셀이 상위 임곗값보다 큰 기울기를 가지면 픽셀을 가장자리로 간주하고, 하위 임곗값보다 낮은 경우 가장자리로 고려하지 않음\n",
    "\n",
    "# apertureSize(소벨 연산자 마스크 크기) : 소벨 연산을 활용하므로, 소벨 마스크의 크기를 설정\n",
    "# L2gradient(L2 그레이디언트) : L2-norm으로 방향성 그레이디언트를 정확하게 계산할지, 정확성은 떨어지지만 속도가 더 빠른 L1-norm으로 계산할지를 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테두리 외삽법 : 이미지 가장자리 부분의 처리 방식\n",
    "# cv2.BORDER_CONSTANT\t    iiiiii | abcdefgh | iiiiiii\n",
    "# cv2.BORDER_REPLICATE\t    aaaaaa | abcdefgh | hhhhhhh\n",
    "# cv2.BORDER_REFLECT\t    fedcba | abcdefgh | hgfedcb\n",
    "# cv2.BORDER_WRAP\t        cdefgh | abcdefgh | abcdefg\n",
    "# cv2.BORDER_REFLECT_101\tgfedcb | abcdefgh | gfedcba\n",
    "# cv2.BORDER_REFLECT101\t    gfedcb | abcdefgh | gfedcba\n",
    "# cv2.BORDER_DEFAULT\t    gfedcb | abcdefgh | gfedcba\n",
    "# cv2.BORDER_TRANSPARENT\tuvwxyz | abcdefgh | ijklmno\n",
    "# cv2.BORDER_ISOLATED\t    관심 영역 (ROI) 밖은 고려하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. HSV(Hue, Saturation, Value)Permalink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSV(Hue, Saturation, Value)\n",
    "\n",
    "# Hue(색상)\n",
    "# 빨간색, 노란색, 파란색 등으로 인식되는 색상 중 하나 또는 둘의 조합과 유사한 것처럼 보이는 시각적 감각의 속성\n",
    "# 0°에서 360°의 범위로 표현되며, 파란색은 220°에서 260° 사이에 위치\n",
    "# OpenCV에서는 0 ~ 179의 범위로 표현(0 ~ 360의 범위는 1 Byte(uint8)의 범위를 벗어나게 되므로 불필요한 메모리 사용을 줄이기 위해 절반으로 표현)\n",
    "\n",
    "# Saturation(채도)\n",
    "# 이미지의 색상 깊이, 색상이 얼마나 선명한(순수한) 색인지를 의미\n",
    "# 아무것도 섞지 않아 맑고 깨끗하며 원색에 가까운 것을 채도가 높다고 표현\n",
    "# 0%에서 100%의 비율로 표현되며, 0%에 가까울수록 무채색, 100%에 가까울수록 가장 선명한(순수한)색\n",
    "# OpenCV에서는 0 ~ 255의 범위로 표현\n",
    "\n",
    "# Value(명도)\n",
    "# 색의 밝고 어두운 정도를 의미\n",
    "# 명도가 높을수록 색상이 밝아지며, 명도가 낮을수록 색상이 어두워짐\n",
    "# 0%에서 100%의 비율로 표현되며, 0%에 가까울수록 검은색, 100%에 가까울수록 가장 맑은색\n",
    "# OpenCV에서는 0 ~ 255의 범위로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/tomato.jpg\", cv2.IMREAD_REDUCED_COLOR_2)\n",
    "\n",
    "# 이미지의 색상 공간을 BGR에서 HSV로 변경\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# 각각의 채널로 분리\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "cv2.imshow(\"Hue\", h)\n",
    "cv2.imshow(\"Saturation\", s)\n",
    "cv2.imshow(\"Value\", v)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hue의 범위 조정하여 특정 색상의 범위만 출력\n",
    "\n",
    "# dst = cv2.inRange(image, 낮은범위, 높은범위)\n",
    "h = cv2.inRange(h, 8, 20) # 주황색 : 약 8~20\n",
    "\n",
    "# 비트연산 and : 픽셀의 이진값이 동일한 영역만 AND 연산하여 반환\n",
    "# dst = cv2.bitwise_and(image1, image2, mask=마스크영역만)\n",
    "orange = cv2.bitwise_and(hsv, hsv, mask = h)\n",
    "\n",
    "# 색상공간 변경\n",
    "orange = cv2.cvtColor(orange, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow(\"orange\", orange)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. 배열 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빨간색 영역이 약 0~5와 약 170~179으로 범위가 두 가지로 나눠져 있음\n",
    "# -> 배열 요소의 범위 설정 함수(cv2.inRange()) 사용에 제한\n",
    "# -> 병합 함수를 사용해 서로 다른 두 범위의 배열을 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/tomato.jpg\", cv2.IMREAD_REDUCED_COLOR_2)\n",
    "hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "# dst = cv2.inRange(image, 낮은범위(색상, 채도, 명도), 높은범위(색상, 채도, 명도))\n",
    "# 빨간색 범위: 약 0~5, 약 170~180 \n",
    "lower_red = cv2.inRange(hsv, (0, 100, 100), (5, 255, 255))\n",
    "upper_red = cv2.inRange(hsv, (170, 100, 100), (180, 255, 255))\n",
    "\n",
    "\n",
    "# dst = cv2.addWeighted(image1, alpha, image2, beta, gamma, dtype = None)\n",
    "# alpha:image1가중치, beta:image2가중치, gamma:추가합, dtype:정밀도(기본갑image1의정밀도따름)\n",
    "# 배열 병합 함수는 알파 블렌딩(alpha blending)을 구현할 수 있어 서로 다른 이미지를 불투명하게 혼합해서 표시할 수 있음\n",
    "added_red = cv2.addWeighted(lower_red, 1.0, upper_red, 1.0, 0.0)\n",
    "\n",
    "red = cv2.bitwise_and(hsv, hsv, mask = added_red)\n",
    "red = cv2.cvtColor(red, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow(\"red\", red)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. 채널 분리 & 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채널 분리(Split)과 병합(Merge)은 영상이나 이미지의 색상 공간의 채널을 분리하거나 합치기 위해 사용\n",
    "# OpenCV의 가산 혼합의 삼원색 기본 배열순서는 BGR\n",
    "# BGR 색상 공간을 B(Blue), G(Green), R(Red)로 분리해 단일 채널을 가진 배열로 반환 가능\n",
    "# 분리된 채널의 값을 변경하거나 순서를 변경해, GB(R/2) 공간을 만들거나 새로운 색상 공간으로 변경할 수도 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"Image/sausage.jpg\", cv2.IMREAD_REDUCED_COLOR_2)\n",
    "\n",
    "# 이미지에서 채널 분리 -> 단일 이미지 배열(흑백 색상) 생성\n",
    "b, g, r = cv2.split(src)\n",
    "\n",
    "# 단일 채널 이미지 배열을 병합해 이미지 생성\n",
    "# 순서가 변경될 경우 이미지 다른 색상으로 표현\n",
    "inverse = cv2.merge((r, g, b))\n",
    "\n",
    "cv2.imshow(\"b\", b)\n",
    "cv2.imshow(\"g\", g)\n",
    "cv2.imshow(\"r\", r)\n",
    "cv2.imshow(\"inverse\", inverse)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy 형식 채널 분리\n",
    "b = src[:, :, 0]\n",
    "g = src[:, :, 1]\n",
    "r = src[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 빈 이미지\n",
    "\n",
    "# src이미지와 같은 크기\n",
    "height, width, channel = src.shape\n",
    "\n",
    "# 0으로 채움(검은화면)\n",
    "zero = np.zeros((height, width, 1), dtype=np.uint8)\n",
    "\n",
    "# red채널 영역을 흑백이미지로\n",
    "bgz = cv2.merge((b, g, zero))\n",
    "\n",
    "# 특정 색상의 이미지 생성\n",
    "# np.full((높이, 너비, 채널), (b, g, r), dtype=정밀도)\n",
    "color = np.full((400, 600, 3), (110, 80, 140), dtype=np.uint8)\n",
    "\n",
    "cv2.imshow(\"bgz\", bgz)\n",
    "cv2.imshow(\"zero\", zero)\n",
    "cv2.imshow(\"color\", color)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch_conda3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f98a42b8bc21e77715747c9bb39187f4c90456d6964ccc6a99ab4ed80b694914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
