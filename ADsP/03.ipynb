{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ⅲ. 데이터 분석 \n",
    "\n",
    "---\n",
    "\n",
    "## 1. 데이터 분석 개요\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 1.1 데이터 분석 기법의 이해\n",
    "\n",
    "#### 1. 데이터 처리 과정\n",
    " - 데이터 분석을 위해서는 데이터 웨어하우스(DW)나 데이터마트(DM)를 통해 분석데이터를 구성\n",
    " - 신규데이터나 DW에 없는 데이터는 기존 운영시스템 에서 직접 가져오거나 운영데이터 저장소(ODS)에서 정제된 데이터를 가져와서 DW의 데이터와 결합하여 활용\n",
    "\n",
    "#### 2. 시각화 기법\n",
    " - 가장 낮은 수준의 분석이지만 잘 사용하면 복잡한 분석보다 더 효율적, 대용량 데이터를 다룰 때와 탐색적 분석(EDA)을 할 때 필수 \n",
    "\n",
    "#### 3. 공간분석\n",
    " - 공간적 차원과 관련된 속성들을 시각화하는 분석으로 지도 위에 관련된 속성들을 생성하고 크기모양, 선 굵기 등을 구분하여 인사이트를 얻음\n",
    "\n",
    "#### 4. 탐색적 자료분석(EDA)\n",
    " - 다양한 차원과 값을 조합해가며 특이점이나 의미있는 사실을 도출하고 분석의 최종목적을 달성해가는 과정\n",
    " - EDA의 4가지 주제 : 저항성의 강조, 잔차 계산, 자료변수의 재표현, 그래프를 통한 현시성\n",
    "\n",
    "#### 5. 통계분석\n",
    " - 어떤 현상을 종합적으로 한눈에 알아보기 쉽게 일정한 체계에 따라 숫자와 표, 그림의 형태로 나타내는 것\n",
    "\n",
    "#### 6. 데이터 마이닝\n",
    " - 대용량의 자료로부터 정보를 요약하고 미래에 대한 예측을 목표로 자료에 존재하는 관계, 패턴, 규칙 등을 탐색하고 이를 모형화함으로써 이전에 알지 못한 유용한 지식을 추출하는 분석 방법\n",
    " - 방법론 : 기계학습(인공신경망, 의사결정나무, 클러스터링, SVM), 패턴인식(연관규칙, 장바구니분석) 등\n",
    "\n",
    "---\n",
    "\n",
    "## 2. R프로그래밍 기초\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 2.1 R소개\n",
    "\n",
    "#### 1. R의 탄생\n",
    " - R은 오픈소스 프로그램으로 통계, 에이터마이닝과 그래프를 위한 언어임\n",
    " - 다양한 최신 통계분석과 마이닝 기능을 제공, 5천개에 이르는 패키지가 수시로 업데이트 됨\n",
    "\n",
    "#### 2. 통계분석 도구의 비교\n",
    "|구분|SAS|SPSS|오픈소스R|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|포로그램비용|유료,고가|유료,고가|오픈소스|\n",
    "|설치용량|대용량|대용량|모듈화로 간단|\n",
    "|다양한 모듈 지원 및 비용|별도구매|별도구매|오픈소스|\n",
    "|최근 알고리즘 및 기술반영|느림|다소 느림|매우 빠름|\n",
    "|학습자료 입수의 편의성|유료 도서 위주|유료 도서 위주|공개 논문 및 자료 많음|\n",
    "|질의를 위한 공개 커뮤니티|NA|NA|매우 활발|\n",
    "\n",
    "#### 3. R의 특징\n",
    " - 오픈소스\n",
    " - 뛰어난 그래픽 및 성능\n",
    " - 시스템 데이터 저장 방식\n",
    " - 모든 운영체제에서 사용 가능\n",
    " - 표준 플랫폼(S언어 기반)\n",
    " - 객체 지향언어이면서 함수형 언어\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 2.2 R기초\n",
    "\n",
    "#### 1. 편리한 기능\n",
    " - R의 작업환경 설정 : setwd('path')\n",
    " - 도움말 : help(함수), ?함수, RSiteSearch('함수명')\n",
    " - 히스토리 : history(), savehistory(file='파일명'), loadhistory(file='파일명')\n",
    "\n",
    "#### 2. 스크립트 사용하기\n",
    " - 한 줄 실행 : Ctrl + R\n",
    " - 여러 줄 실행 : 드래그 + Ctrl + R\n",
    " - 주석처리 : #\n",
    "\n",
    "#### 3. 패키지\n",
    " - 패키지 : R함수, 데이터 및 코드의 모임\n",
    " - 패키지 자동설치 : install.packages('패키지명')\n",
    " - 패키지 수동설치 : install.packages('패키지명'. '패키지위치')\n",
    "\n",
    "#### 4. 배치 실행\n",
    " - 매일 실행되어야 하는 프로그램을 시스템에서 프로세스에서 자동으로 구동하는 작업\n",
    " - 배치파일 실행 명령 : 윈도우 창에서 batch.R 실행파일이 있는 위치에서 R CMD BATCH batch.R\n",
    " - Path 지정 : 내컴퓨터 오른쪽 마우스 클릭 -> 속성 -> 고급시스템 설정 -> 환경변수 -> 변수명 Path 클릭 -> R실행파일위치 추가 -> 저장\n",
    "\n",
    "#### 5. 변수 다루기\n",
    " - R에서는 변수명만 선언하고 값을 할당하면 자료형태를 스스로 인식하고 선언\n",
    " - 화면에 프린트하고자 할 때, print()를 사용해도 되지만 변수 값만 표현해도 내용을 출력 해줌\n",
    " - 변수에 값을 할당할 때, 대입연산자(<-) 사용 가능\n",
    " - 메모리에 저장된 변수 확인 : ls()\n",
    " - 변수 삭제 : rm()\n",
    "\n",
    "#### 6. 기본적인 통계량 계산\n",
    "|평균|중간값|표준편차|분산|공분산|상관계수|\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "|mean()|median()|sd()|var()|cov()|cor()|\n",
    "\n",
    "#### 7. 함수의 생성 및 활용\n",
    " - R은 함수형 언어이기 때문에 직접 함수 생성 및 활용 가능\n",
    " - 표현식 : function(매개변수1, 매개변수2, ...), 표현식 2줄 이상인 경유 {}로 묶어서 범위 설정\n",
    " - 표현식은 변수 할당, 조건문과 반복문 그리고 리턴값으로 구성\n",
    "\n",
    "#### 8. 연산자 우선순위\n",
    "\n",
    "<img src=\"./Data/연산자우선순위.png\" width=\"700\" height=\"800\">\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 2.3 입력과 출력\n",
    "\n",
    "#### 1. 데이터 입력과 출력\n",
    " - R은 다양한 데이터를 불러와 분석 수행 가능\n",
    " - 부동소수점 표현시 7자리 수가 기본값. option() 또는 digit='숫자'를 지정해 변경 \n",
    " - 문자열을 파일로 저장 : cat('저장할 문자열', file='파일명')\n",
    " - R에서는 역슬래시(\\\\)를 인식하지 못함, 슬래시(/) 또는 이중 역슬래시로 파일 경로 지정\n",
    "\n",
    "#### 2. 외부 파일 입력과 출력\n",
    " - 고정자리 변수 파일 : read.fwf('파일명', width=c(w1,w2,...))\n",
    " - 구분자 변수 파일 : read.table('파일명', sep='구분자')\n",
    " - csv 파일 읽기 : read.csv('파일명', header=T) # 1행이 변수인 경우:header=T\n",
    " - csv 파일 출력 : write.csv(데이터 프레임, '파일명')\n",
    "\n",
    "#### 3. 웹 페이지(Web Page)에서 데이터 ㅣㅇㄺ어오기\n",
    " - 파일 다운로드 : read.csv('url')\n",
    " - ftp에서 파일 다운로드 : read.csv('url')\n",
    " - html에서 테이블 : readHTMLTable('url')\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 2.4 데이터 구조와 데이터 프레임\n",
    "\n",
    "#### 1. 데이터 구조의 정의\n",
    "\n",
    "|특징|벡터|리스트|데이터프레임|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|원소 자료형|동질적|이질적|이질적|\n",
    "|원소를 위치로 인덱싱|가능|가능|가능|\n",
    "|인덱싱으로 여러 개 원소로 구성된 하위 데이터 생성|가능|가능|가능|\n",
    "|원소들에게 이름 부여|가능|가능|가능|\n",
    "\n",
    " - 단일값(Scalars) : 원소가 하나인 벡터로 인식/처리\n",
    " - 행렬(Matrices) : 원소가 하나인 벡터로 인식/처리\n",
    " - 배열(Arrays) : 3원소가 하나인 벡터로 인식/처리\n",
    " - 요인(Factors) : 고유값(Value)이 요인의 수준(Level)으로 구성된 벡터(범주형 변수, 집단 분류)\n",
    "\n",
    "#### 2. 리스트 다루기\n",
    " - 리스트 원소 선택 : L[[n]], L[[\"name\"]], L$name\n",
    "\n",
    "#### 3. 행렬 다루기\n",
    " - 행렬 설정 : dim(vec)<-c(2,3)\n",
    " - 행과 열 이름 붙이기 : rownames(mtrx)<-c('rowname1','rowname2',...), colnames(mtrx)<-c('colname1','colname2',...)\n",
    "\n",
    " #### 4. 데이터 구조 변환\n",
    "\n",
    "<img src=\"./Data/데이터구조변환.png\" width=\"800\" height=\"500\">\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 2.5 데이터 변형\n",
    "\n",
    "#### 1. 집단으로 분할하기\n",
    " - 벡터 : split(vec, fac) - qprxjrkqtrhk vorxjrkqtdml rlfdlrk rkxdkdi gka\n",
    " - 데이터프레임 : split(df,fac)\n",
    "\n",
    "#### 2. 함수 적용하기\n",
    " - 벡터, 행렬 : apply(mtr, 1, func), apply(mtr, 2, func)\n",
    " - 리스트 : lapply(lst, func), sapply(lst, func)\n",
    " - 데이터프레임 : lapply(dfm, func), sapply(dfm, func), apply(dfm, 1or2, func)\n",
    " \n",
    "#### 3. 집단별로 함수 적용하기\n",
    " - tapply(vec, fac, func)\n",
    " - by(dfm, fac, func)\n",
    "\n",
    "#### 4. 병령 벡터들과 리스트들에 함수 적용하기\n",
    "\n",
    "#### 5. 문자열 다루기\n",
    " - 문자열 길이 : nchar('문자열')\n",
    " - 벡터의 길이 : length(vec)\n",
    " - 문자열 연결하기 : paste('단어', '문장', scalar)\n",
    " - 하위 문자열 추출하기 : substr('문자열', 시작번호, 끝번호)\n",
    " - 구분자로 문자열 추출하기 : strsplit('문자열', 구분자)\n",
    " - 문자열 대체하기 : sub('대상문자열', '변경문자열', s), gsub('대상문자열', '변경문자열', s)\n",
    "\n",
    "#### 6. 날짜 다루기\n",
    " - 문자열 -> 날짜 : as.Date('2014-12-25'), as.Date('2014/12/25', format=\"%m/%d/%Y\")\n",
    " - 날짜 -> 문자열 : format(Sys.Date(), format=\"%m/%d/%Y\")\n",
    " - format 인자값\n",
    "   - %b:축약된 월이름('Jan'), %B:전체 월 이름(\"January\")\n",
    "   - %d:두 자리 숫자 일(\"31\")\n",
    "   - %m:두 자리 숫자 월(\"12\")\n",
    "   - %y:두 자리 숫자 년('14')\n",
    "   - %Y:네 자리 숫자 년(\"2014\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 데이터 마트\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 3.1 데이터 변경 및 요약 \n",
    "\n",
    "#### 1. 데이터 마트\n",
    " - 데이터 웨어하우스와 사용자 사이의 중간층에 위치\n",
    " - 하나의 주제 또는 하나의 부서 중심의 데이터 웨어하우스\n",
    "\n",
    "#### 2. 요약변수와 파생변수\n",
    " - 요약 변수\n",
    "   - 정의 : 수집된 정보를 분석에 맞게 종합한 변수, 가장 기본적인 변수, 많은 모델에 공통으로 사용(재활용성 높음)\n",
    "   - 예시 : 기간별 구매 금액, 횟수, 여부/위클리쇼퍼/상품별 구매금액, 횟수, 여부/상품별 구매순서/유통채널별 구매금액/단어빈도/초기 행동변수/트랜드 변수/결측값과 이상값 처리/연속형 변수의 구간화\n",
    " - 파생변수\n",
    "   - 정의 : 사용자가 특정 조건을 만족하거나 특정 함수에 의해 값을 만들어 의미를 부여한 변수, 주관적일 수 있어 타당성을 갖출 필요 있음\n",
    "   - 예시 : 근무시간 구매지수/주 구매 매장/주 활동 지역/ 주 구매 상품/구매상품 다양성/선호 가격대/시즌 선호 고객/라이프 스테이지/라이프 스타일/휴면가망/최대가치/최적 통화시간\n",
    "\n",
    "#### 3. reshape 패키지\n",
    " - 2개의 핵심적인 함수로 구성\n",
    "   - melt() : 쉬운 casting을 위해 데이터를 적당한 형태로 만둘어주는 함수\n",
    "   - cast() : 데이터를 원하는 형태로 계산 또는 변형시켜주는 함수\n",
    " - 변수를 조합해 변수명을 만들고 변수들을 시간, 상품 등의 차원에 결합해 다양한 요약변수와 파생변수를 쉽게 생성하여 데이터 마트를 구성할 수 있게 해주는 패키지\n",
    "\n",
    "#### 4. sqldf 패키지\n",
    " - R에서 sql 명령어를 사용가능하게 해주는 패키지, SAS의 proc sql과 같은 기능\n",
    " - head([df]) -> sqldf('select * from [df] limit 6')\n",
    " - subset([df], [col] %in% c('BF', 'HF')) -> sqldf('select * from [df] where [col] in ('BF', 'HF')')\n",
    " - merge([df1],[df2]) -> sqldf(\"select * from [df1], [df2]\")\n",
    "\n",
    "#### 5. plyr 패키지\n",
    " - apply 함수를 기반으로 데이터와 출력변수를 동시에 배열로 치환하여 처리하는 패키지\n",
    " - split - apply - combine 방식으로 데이터를 분리하고 처리한 다음, 다시 결합하는 등 필수적인 데이터 처리 기능 제공\n",
    "\n",
    "<img src=\"./Data/plyr.png\" width=\"600\" height=\"300\">\n",
    "\n",
    "#### 6. data.table\n",
    " - R에서 가장 많이 사용하는 데이터 핸들링 패키지 중 하나로 대용량 데이터의 탐색, 연산, 병합에 유용\n",
    " - 기존 data.frame 방식보다 월등히 빠른 속도\n",
    " - 특정 column을 key 값으로 색인을 지정한 후 데이터를 처리\n",
    " - 빠른 grouping과 ordering, 짧은 문장 지원 측면에서 데이터프레임보다 유용\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 3.2 데이터 가공\n",
    "\n",
    "#### 1. 변수의 구간화\n",
    " - 신용평가모형, 고객 세분화 등의 시스템으로 모형을 적용하기 위해 각 변수들을 구간화하여 점수를 적용하는 방식 활용\n",
    " - 변수의 구간화를 위한 rule이 존재(10진수 단위, 보통 5개 구간으로, 7개 이상은 지양)\n",
    "\n",
    "#### 2. 변수 구간화의 방법\n",
    " - binning : 연속형 변수를 범주형 변수로 변환하기 위해 50개 이하의 구간에 동일한 수의 데이터를 할당하여 의미를 파악하면서 구간을 축소하는 방법\n",
    " - 의사결정나무 : 모형을 통해 연속형 변수를 범주형 변수로 변환하는 방법\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 3.3 기초 분석 및 데이터 관리\n",
    "\n",
    "#### 1. 결측값 처리\n",
    " - 변수에 데이터가 비어 있는 경우 : NA, ., 99999999, Unknown, Not Answer 등으로 표현\n",
    " - 단순 대치법 \n",
    "   - completes analysis : 결측값의 레코드를 삭제\n",
    "   - 평균대치법 : 관측 및 실험을 통해 얻어진 데이터의 평균으로 대치\n",
    "     - 조건부 : 관측 데이터의 평균으로 대치\n",
    "     - 비조건부 : 회귀분석을 통해 데이터를 대치\n",
    "\n",
    "   - 단순확률 대치법 : 평균대치법에서 추정량 표준 오차의 과소 추정문제를 보완한 방법으로 Hot-deck 방법, nearest Neighbor 방법이 있음\n",
    " - 다중 대치법 : 단순 대치법을 m번 실시하여, m개의 가상적 자료를 만들어 대치하는 방법\n",
    " \n",
    "#### 2. R의 결측값 처리 관련 함수\n",
    " - complet.cases() : 데이터 내 레코드에 결측값이 있으면 FALSE, 없으면 TRUE 반환\n",
    " - is.na() : 결측값이 NA인지의 여부를 TRUE/FALSE로 반환\n",
    " - knnlmputation()(DMwR 패키지) : NA값을 가운데 값(central value)으로 대치(숫자:중위수, factor:최빈값)\n",
    " - amelia()(Amelia 패키지) : time-series-cross-sectional data set(여러 국가에서 매년 측정된 자료)에서 활용\n",
    " \n",
    "#### 3. 이상값 처리\n",
    " - 이상값\n",
    "   - 의도하지 않은 현상으로 입력된 값 or 의도된 극단값 -> 활용 가능\n",
    "   - 잘못 입력된 값 or 의도하지 않은 현상으로 입력된 값이지만 분석 목적에 부합되지 않는 값 -> bad data(제거)\n",
    " - 이상값의 인식\n",
    "   - ESD(Extreme Studentized Deviation) : 평균으로부터 3표준편차 떨어진 값\n",
    "   - 기하평균-2.5x표준편차 < data < 기하평균+2.5x표준편차\n",
    "   - Q1-1.5(Q3-Q1) < data < Q1+1.5(Q3-Q1)를 벗어나는 데이터\n",
    " - 이상값의 처리\n",
    "   - 절단 : 이상값이 포함된 레코드를 삭제\n",
    "   - 조정 : 이상값을 상한 또는 하한 값으로 조정\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 통계 분석\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 4.1 통계분석의 이해\n",
    "\n",
    "#### 1. 통계\n",
    " - 통계 : 특정집단을 대상으로 수행한 조사나 실험을 통해 나온 결과에 대한 요약된 형태의 표현\n",
    " - 통계자료 획득방법 : 총 조사, 표본조사\n",
    " - 표본 추출 방법 : 단순랜덤추출, 계통추출법, 집락추출법, 층화추출법\n",
    " - 자료 측정 방법 : 명목척도, 순서척도, 구간척도, 비율척도\n",
    "\n",
    "#### 2. 통계분석\n",
    " - 기술통계 : 평균, 표준편차, 중위수, 최빈값, 그래프\n",
    " - 통계적 추론 : 모수추정, 가설검정, 예측\n",
    "\n",
    "#### 3. 확률 및 확률 분포\n",
    " - 확률변수 : 특정 값이 나타날 가능성이 확률적으로 주어지는 변수\n",
    " - 이산형 확률분포 : 베르누이분포, 이항분포, 기하분포, 다항분포, 포아송분포\n",
    " - 연속형 확률분표 : 균일분포, 정규분포, 지수분포, t분포, F분포, 카이제곱(X^2)분포\n",
    "\n",
    "#### 4. 추정 및 가설검정\n",
    " - 추정 : 표본으로부터 미지의 모수를 추측하는 것\n",
    " - 점추정\n",
    "   - '모수가 특이한 값일 것'이라고 추정\n",
    "   - 평균, 표준편차, 중앙값 등을 추정\n",
    "   - 조건 : 불편성, 효율성, 일치성, 충족성\n",
    " - 구간추정\n",
    "   - 점추정을 보완하기 위해 모수가 특정 구간에 있을 것이라고 추정하는 것\n",
    "   - 모분산을 알거나 대표본의 경우 표준정규분포 활용\n",
    "   - 모분산을 모르거나 소표본의 경우 t분포 활용\n",
    " - 가설검정 : 모집단에 대한 가설을 설정한 뒤, 그 가설의 채택여부를 결정하는 방법\n",
    "   - 귀무가설(H0) vs 대립가설(H1)\n",
    "   - 1종 오류 : 귀무가설 H0이 옳은데도 귀무가설을 기각하게 되는 오류(H0참 H1거짓)\n",
    "   - 2종 오류 : 귀모가설 H0이 옳지 않은데도 귀무가설을 채택하게 되는 오류(H1참 H0거짓)\n",
    "   - 1종 오류의 크기기를 고정시키고 2종 오류가 최소가 되도록 기각역을 설정\n",
    "\n",
    "#### 5. 비모수 검정\n",
    " - 비모수 검정 : 모집단의 분포에 대한 아무 제약을 가하지 않고 검정을 실지\n",
    " - 가설 설정 방법 : '분포의 형태가 동일하다', '분포의 형태가 동일하지 않다'라는 식으로 가설을 설정\n",
    " - 검정 방법 : 순위나 두 관측값 차이의 부호를 이용해 검정\n",
    "   - 예 : 부호검정, 윌콕슨의 순위합검정, 윌콕슨의 부호순위합검정, 만-위트니의 U검정, 런검점, 스피어만의 순위상관계수\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 4.2 기초 통게 분석 \n",
    "\n",
    "#### 1. 기술 통계\n",
    " - 기술 통계 : 자료의 특성을 표, 그림, 통계량 등을 사용해 쉽게 파악할 수 있도록 정리/요약하는 것\n",
    " - 통계량에 의한 자료 정리\n",
    "   - 중심 위치의 측도 : 평균, 중앙값, 최빈값\n",
    "   - 산포의 측도 : 분산, 표준편차, 범위, 사분위수범위, 변동계수, 표준오차\n",
    "   - 분포의 평태 : 왜도, 첨도\n",
    " - 그래프를 통한 자료 정리\n",
    "   - 범주형 자료 : 막대그래프, 파이차트, 모자이크 플랏 등\n",
    "   - 연속형 자료 : 히스토그램, 줄기-잎 그림, 상자그림\n",
    "\n",
    "#### 2. 인과관계의 이해\n",
    " - 용어\n",
    "   - 종속변수, 독립변수, 산점도\n",
    "   - 산점도에 확인할 수 있는 것 : 두 변수의 선형관계, 두 변수의 함수관계, 이상값의 존재여부와 집단 갯수\n",
    " - 공분산\n",
    "   - 두 변수간의 상관 정도를 상관계수를 통해 확인할 수 있음\n",
    "   - Cov(X, Y) = E[(X-ux)(Y-uy)]\n",
    "\n",
    "#### 3. 상관분석\n",
    " - 정의와 특성\n",
    "   - 상관분석 : 두 변수 간의 관계를 상관계수를 이용하여 알아보는 분석 방법\n",
    "   - 상관계수가 1에 가까울수록 강한 양의 상관관계, -1에 가까울수록 강한 음의 상관관계\n",
    "   - 상관계수가 0에 가까울수록 상관관계 없음\n",
    " - 유형\n",
    "   - 피어슨 : 연속형 변수, 정규성 가정\n",
    "   - 스피어만 : 순서형 변수, 비모수적 방법\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 4.3 회귀분석\n",
    "\n",
    "#### 1. 회귀분석의 개요\n",
    " - 정의\n",
    "   - 하나 또는 그 이상의 독립변수들이 종속변수에 미치는 영향을 추정할 수 있는 통계기법\n",
    "   - yi= b0 + bixi + ei, i=1,2,...n, ei - N(0,감마^2), y=종속변수, x=독립변수\n",
    "   - 독립변수가 1개 : 단순선형회귀분석, 2개 이상 : 다중선형회귀분석\n",
    "   - 최소제곱법 : 측정값을 기초로 제곱 합을 만들고 그것의 최소인 값을 구하여 처리하는 방법, 잔차제곱이 가장 작은 선을 선택\n",
    " - 회귀분석의 검정\n",
    "   - 회귀식에 대한 검정 : F-검정\n",
    "   - 회귀계수들에 대한 검증 : t-검정\n",
    "   - 모형의 설명력은 결저계수(R^2)으로 알 수 있음, R^2=회귀제곱항/전체제곱항 = SSR/SST, 0<=R^2<=1\n",
    "   - 단순회귀분석의 결정계수는 상관계수값의 제곱과 같음\n",
    " - 선형회귀분석\n",
    "   - 가정 : 선형성, 독립성, 등분산성, 비상관성, 정상성\n",
    "   - 다중선형회귀분석의 다중공선성 : 설명변수들 사이에 선형관계 존재하면 회귀계수 정확한 추정 곤란\n",
    "   - 다중공선성 검사 방법 : 분산팽창요인(VIF)-10보다크면 심각한 문제, 상태지수-10이상문제/30이상 심각, 선형관계 강하면 변수 제거\n",
    " - 회귀분석의 종류\n",
    "   - 단순회귀, 다중회귀, 로지스틱회귀, 다항회귀, 곡선회귀, 비선형회귀\n",
    " - 변수선택법\n",
    "   - 모든 가능한 조합 : 모든 가능한 독립변수들의 조합에 대한 회귀모형을 분석해 가장 적합한 모형 선택\n",
    "   - 전진선택법 : 숭요하다고 생각되는 변수부터 차례로 모형에 추가\n",
    "   - 후진소거법 : 모두 포함 -> 가장 적은 영향을 주는 변수부터 제거\n",
    "   - 단계별방법 : 전진선택법 + 새변수에 의해 기존변수 중요도 약화되면 해당 변수 제거 등 추가/삭제 변수 없을 때 중단\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 4.4 시계열 분석\n",
    "\n",
    "#### 1. 시계열 자료\n",
    " - 개요\n",
    "   - 시계열 자료 : 시간의 흐름에 따라 관찰된 값들\n",
    "   - 시계열 데이터 분석 목적 : 미래의 값을 예측, 특성 파악(경향, 주기, 계절성, 불규칙성 등)\n",
    " - 정상성(3가지 조건 모두 만족) : 평균 일정(모든 시점), 분산 일정, 공분산도 특정 시점에서 t, s에 의존하지 않고 일정\n",
    " - 시계열 모형\n",
    "   - 자기회귀모형 : p시점 전의 자료가 현재 자료에 영향을 주는 모형\n",
    "   - 이동평균모형 : 같은 시점의 백색잡음과 바로 전 시점의 백색잡음의 결합으로 이뤄진 모형\n",
    "   - 자기회귀누적이동평균모형\n",
    " - 분해 시계열\n",
    "   - 시계열에 영향을 주는 일반적인 요인을 시계열에서 분리해 분석하는 방법\n",
    "   - 추세요인 : 형태가 오르거나 또는 내리는 추세, 선형, 이차식, 지후형태\n",
    "   - 계절요인 : 요일, 월, 사분기 별로 변화하여 고정된 주기에 따라 자료가 변화\n",
    "   - 순환요인 : 명백한 경제적, 자연적 이유없이 알려지지 않은 주기로 자료가 변화\n",
    "   - 불규칙요인 : 위 세가지의 요인으로 설명할 수 없는 회귀분석에서 오차에 해당하는 요인\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 4.5 다차원 척도법과 주성분분석\n",
    "\n",
    "#### 1. 다차원 척도법\n",
    " - 정의 및 목적\n",
    "   - 군집분석과 같이 개체들을 대상으로 변수들을 측정한 후, 개체들 사이ㅢ 유사성/비유사성을 측정하여 개체들을 2차원 또는 3차원 공간상에서 점으로 표현하는 분석방법\n",
    "   - 목적 : 개체들의 비유사성을 이용하여 2차원 공가상에 점으로 표시하고 개체들 사이의 집단화를 시각적으로 표현\n",
    "\n",
    " - 방법\n",
    "   - 개체들의 거리 계산은 유클리드 거리행렬을 활용\n",
    "   - STRESS : 개체들을 공간상에 표현하기 위한 방법으로 STRESS나 S-STRESS를 부적합도 기준으로 사용\n",
    "     - 최적모형의 적합은 부적합도를 최소로 하는 방법으로 일정 수준 이하로 될 때까지 반복해서 수행\n",
    " - 종류\n",
    "   - 계량적 MDS : 데이터가 구간척도나 비율척도인 경우 활용(전통적 다차원척도법)\n",
    "   - 비계량적 MDS : 데이터가 순서척도인 경우 활용\n",
    "\n",
    "#### 2. 주성분분석\n",
    " - 정의 및 목적\n",
    "   - 상관관계가 있는 변수들을 결합해 상관관계가 없는 변수로 분산을 극대화하는 변수로, 선형결합으로 변수를 축약, 축소하는 기법\n",
    "   - 목적 : 여러 변수들을 소수의 주성분으로 축소하여 데이터를 쉽게 이해하고 관리, 연산속도 개선, 다중공선성 최소화\n",
    " - 주성분분석 vs 요인분석\n",
    "   - 요인분석 : 등간척도(비율척도)로 두 개 이상의 변수들을 잠재되어 있는 공통 인자를 찾아내는 기법\n",
    "   - 공통점 : 모두 데이터를 축소하는데 활용, 몇 개의 새로운 변수들로 축소\n",
    "   - 차이점 : 변수들 간의 중요도 차이 유무\n",
    "\n",
    " - 주성분의 선택법\n",
    "   - 누적기여율이 85%이상이면 주성분의 수로 결정할 수 있음\n",
    "   - scree plot에서 고유값이 수평을 유지하기 전 단계로 주성분의 수를 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 정형데이터 마이닝 \n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 5.1 데이터 마이닝의 개요 \n",
    "\n",
    "#### 1. 데이터 마이닝\n",
    " - 개요\n",
    "   - 정의 : 대용량 데이터에서 의미 있는 패턴을 파악하거나 예측하여 의사결정에 활용하는 방법\n",
    "   - 통계분석과 차이점 : 가설이나 가정에 따른 분석, 검증을 하는 통계분석과 달리 데이터마이닝은 다양한 수리 알고리즘을 이용해 데이터베이스의 데이터로부터 의미있는 정보를 추출\n",
    "   - 활용분야 : 분류, 예측, 군집화, 시각화 등\n",
    " - 분석방법\n",
    "   - 지도학습 : 의사결정나무, 인공신경망, 로지스틱회귀분석, 최근접이웃법, 사례기본 추론\n",
    "   - 비지도학습 : OLAP, 연관규칙분석, 군집분석, SOM\n",
    " - 데이터 마이닝 추진단계\n",
    "   - 목적설정 -> 데이터준비 -> 데이터가공 -> 기법적용 -> 검증\n",
    " - 데이터 분할 : train:50%, val:30%, test:20%\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 5.2 분류분석\n",
    "\n",
    "#### 1. 분류분석과 예측분석\n",
    " - 개요\n",
    "   - 공통점 : 레코드의 특정 속성의 값을 미리 알아 맞히는 것\n",
    "   - 차이점\n",
    "     - 분류-범주형속성 : 내신 등급 예측, 신용등급 예측\n",
    "     - 예측-연속형속성 : 수능 점수 예측, 연 매출액 예측\n",
    "   - 분류 모델링 : 신용평가모형, 사기방지모형, 이탈모형, 고객세분화\n",
    "   - 분류 기법 : 로지스틱 회귀분석, 의사결정나무, CART(분류회귀나무), C5.0, 베이지안분류, 인공신경망, SVM, knn, 규칙기반의 분류와 사례기반추론\n",
    " \n",
    "#### 2. 의사결정나무\n",
    " - 정의와 특징\n",
    "   - 분류함수를 의사결정 규칙으로 이뤄진 나무모양으로 그리는 방법\n",
    "   - 의사결정문제를 시각화해 의사결정이 이뤄지는 시점과 성과를 한눈에 볼 수 있음\n",
    "   - 주어진 입력값에 대해 출력값을 예측하는 모형으로 분류나무와 회귀나무 모형이 있음\n",
    "   - 특징\n",
    "     - 계산결과가 의사결정나무에 직접 나타나게 돼 분석이 간편함\n",
    "     - 분류정확도 좋음\n",
    "     - 대용량데이터에서도 빠름(계산 복잡X)\n",
    "     - 이상치에 민감하지 않음\n",
    "     - 상관성이 높은 변수들이 있어도 크게 영향받지 않음\n",
    " - 활용\n",
    "   - 세분화 : 데이터를 비슷한 특성을 갖는 몇 개의 그룹으로 분할해 그룹별 특성을 발견\n",
    "   - 분류 : 관측개체를 여러 예측변수들에 근거해 목표변수의 범주를 몇 개의 등급으로 분류하고자 하는 경우\n",
    "   - 예측 : 자료에서 규칙을 찾아내고 이를 이용해 미래의 사건을 예측하고자 하는 경우\n",
    "   - 차원축소 및 변수선택 : 매우 많은 수의 예측벼수 중 목표변수에 영향을 미치는 변수들을 골라내고자 하는 경우\n",
    "   - 교호작용효과의 파악 : 여러개의 예측변수들을 결합해 목표 변수에 작용하여 파악하고자 하는 경우\n",
    "   - 범주의 병합 또는 연속형 변수의 이산화 : 범주형 목표변수의 범주를 소수의 몇 개로 병합하거나 연속형 목표변수를 몇 개의 등급으로 이산화 하고자 하는 경우\n",
    " - 의사결정나무의 분석 과정\n",
    "   - 분석 단계 : 성장 -> 가지치기 -> 타당성평가 -> 해석 및 예측\n",
    "   - 가지치기 : 너무 큰 나무 모형은 과대적합하고 너무 작은 나무 모형은 과소적합할 위험이 있어 마디에 속한 자료가 일정 수 이하일 경우 분할을 정지하고 가지치기 실시\n",
    "   - 불순도에 따른 분할 측도 : 카이제곱 통계량, 지니지수, 엔트로피 지수\n",
    " - 의사결정나무 분석의 종류\n",
    "   - CART(Classification and Regression Tree)\n",
    "     - 목적변수가 범주형인 경우 지니지수, 연속형인 경우 분산을 통해 이진분리를 사용 \n",
    "     - 개별 입력변수 뿐만 아니라 입력변수들의 선형결합들 중 최적의 분리를 찾을 수 있음\n",
    "   - C4.5/C5.0\n",
    "     - 다지분리가 가능하고 범주형 입력 변수의 범주 수만큼 분리가능\n",
    "     - 불순도의 측도로 엔트로피 지수 사용\n",
    "   - CHAID(CHi-squared Automatic Interaction Detection)\n",
    "     - 가지치기를 하지 않고 적당한 크기에서 나무모형의 성장을 중지하며 입력변수가 반드시 범주형 변수여야 함\n",
    "     - 불순도의 측도로 카이제곱 통계량 사용 \n",
    "\n",
    "#### 3. 앙상블 기법\n",
    " - 개요\n",
    "   - 주어진 자료로부터 여려개의 예측모형들을 만든 후 조합하여 하나의 최종예측모형을 만드는 방법\n",
    "   - 다중 모델 조합, Classifier Combination 방법이 있음\n",
    "   - 학습 방법의 불안정성을 해셜하기 위해 고안된 기법\n",
    "   - 가장 불안정성을 가지는 기법은 의사결정나무, 가장 안정성을 가지는 기법은 1-nearest neighbor\n",
    " - 기법의 종류\n",
    "   - 배깅(begging:bootstrap aggregating)\n",
    "     - 여러개의 부트스트랩 자료를 생성하고 각 부트스트랩 자료의 예측모형 결과를 결합하여 결과를 선정\n",
    "     - 배깅은 훈련자료를 모집단으로 생각하고 평균 예측모형을 구한 것과 같아 분산을 줄이고 예측력을 항상 시킬 수 있음\n",
    "   - 부스팅(boosting)\n",
    "     - 예측력이 약한 모형들을 결합하여 강한 예측모형을 만드는 방법\n",
    "     - 훈련오차를 빨리 그리고 쉽게 줄일 수 있고, 예측오차의 향상으로 배깅에 비해 뛰어난 예측력을 보임\n",
    "   - 랜덤 포레스트\n",
    "     - 의사결정나무의 특징이 분산이 크다는 점을 고려하여 배깅과 부스팅보다 더 많은 무작위성을 주어 약한 학습기들을 생성한 후 이를 선형 결합하여 최종 학습기를 만드는 방법\n",
    "     - 이론적 설명이나 해석이 어렵지만 예측력이 높음\n",
    "     - 입력변수가 많은 경우 더 좋은 예측력을 보임\n",
    "\n",
    "#### 4. 성과분석\n",
    "\n",
    " - 오분류표를 통한 모델 평가\n",
    "\n",
    "<img src=\"./Data/혼동행렬이용한평가지표.png\">\n",
    "\n",
    " - ROC(Receiver Operation characteristic)\n",
    "   - 민감도(재현율)과 1-특이도(거짓긍정률)를 활용하여 모형을 평가\n",
    "   - AUROC : ROC커브 밑부분의 넓이 = (AR+1)/2\n",
    "\n",
    "#### 5. 인공신경망\n",
    " - 신경망의 연구\n",
    "   - 인공신경망은 뇌를 기반으로 한 추론모델\n",
    "   - 퍼셉트론이라는 인공세포 개발 -> 비선형성의 한계점 발생 - XOR문제\n",
    "   - 역전파 알고리즘을 활용하여 비선형성을 극복한 다층 퍼셉트론으로 새로운 인공신경망 모형 등장\n",
    " - 뉴런\n",
    "   - 인공신경망은 뉴런이라는 단순하지만 복잡하게 연결된 프로세스로 이루어져 있음\n",
    "   - 뉴런은 가중치가 있는 링크들로 연결되어있으며, 뉴런은 여러 개의 입력신호를 받아 하나의 출력신호를 생성\n",
    "   - 뉴런은 전이함수(활성화함수)를 사용\n",
    "     - 뉴런은 입력 신호의 가중치 합을 계산하여 임계값과 비교\n",
    "     - 가중치 합이 임계값보다 작으면 뉴런의 출력은 -1, 같거나 크면 +1을 출력함\n",
    "     - 시그모이드함수, relu함수, 계단함수, 부호함수 등\n",
    " - 신경망모형 구축 시 고려사항\n",
    "   - 입력변수\n",
    "     - 신경망모형은 복잡성으로 인해 입력자료의 선택에 매우 민감\n",
    "     - 범주형 변수 : 각 범주의 빈도가 일정수준 이상이고, 각 범주의 빈도가 일정할 때 활용(가변수화 사용-남자:1, 여자:2)\n",
    "     - 연속형 변수 : 입력 값의 범위가 변수들간에 큰 차이가 없을 때 활용, 분포가 대칭이 아니면 좋지않은 결과 도출, 변환 또는 범주화 활용\n",
    "   - 가중치 초기값\n",
    "     - 역전파 알고리즘의 경우 초기값에 따라 결과가 많이 달라져 초기값 선택이 매우 중요\n",
    "     - 가중치가 0이면 시그모이드함수는 선형이 되고 신경망 모형도 선형모형이됨\n",
    "     - 초기값은 0 근처의 랜덤값으로 선정하고 초기에는 선형모형에서 가중치가 증가하면서 비선형으로 변경됨\n",
    "   - 예측값 선정\n",
    "     - 비용함수 R(θ)는 비볼록함수이고 여러 개의 국소 최소값들을 가짐\n",
    "     - 랜덤하게 선택된 여러 개의 초기값에 대한 신경망을 적합한 후 얻은 해들을 비교하여 가장 오차가 작은 것을 선택하여 최종 예측값을 얻거나 평균 또는 최빈값을 구하여 최종 예측값으로 선성\n",
    "     - 훈련자료에 대하여 배깅을 적용하여 최종 예측치를 선정\n",
    "   - 학습률 : 상수값을 사용하며 처음에는 큰 값으로 정하고 반복이 진행되어 해가 가까울 수록 0에 수렴\n",
    "   - 은닉층, 은닉노드의 수\n",
    "     - 은닉층과 은닉노드가 많으면 과대적합, 넉으면 과소적합 문제 발생\n",
    "     - 은익층 수 결정 : 은닉층이 하나인 신경망은 범용근사자이므로 가급적이면 하나로 선성\n",
    "     - 은닉노드 수 결정 : 적절히 큰 값으로 결정하고 가중치를 감소하면서 모수에 대한 벌점화 적용\n",
    "   - 과대적합문제\n",
    "     - 신경망은 많은 가중치를 추정해야 하므로 과대적합 문제가 빈번\n",
    "     - 해결방법 : 조기종료(검증오차가 증가하기 시작하면 반복을 중지), 벌점화 기법(가중치 감소)\n",
    "\n",
    "#### 6. 로지스틱 회귀분석\n",
    " - 개요\n",
    "   - 반응변수가 범주형인 경우에 적용되는 회귀분석모형\n",
    "   - 새로운 설명변수(또는 예측변수)가 주어질 때 반응 변수의 각 범주(또는 집단)에 속할 확률이 얼마인지를 추정하여, 추정확률을 기준치에 따라 분류하는 목적으로 활용\n",
    "   - 이때 모형의 적합을 통해 추정된 확률을 사후확률이라고 함\n",
    "   - glm()함수를 활용하여 로지스틱 회귀분석을 실행함\n",
    "   - glm(종속변수 ~ 독립변수1+...+독립변수k, family=binomial, data=dataset명)\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 5.3 군집분석\n",
    "\n",
    "#### 1. 군집분석\n",
    "\n",
    " - 개요\n",
    "   - 각 객체의 유사성을 측정하여 유사성이 높은 대상집단을 분류하고, 군집에 속한 객체들의 유사성과 서로 다른 군집에 속한 객체간의 상이성을 규명하는 분석 방법\n",
    "   - 특성에 따라 고개을 여러 개의 배타적인 집단으로 나누는 것으로 군집의 개수, 구조에 대한 가정 없이 데이터로부터 거리 기준으로 군집화 유도\n",
    " - 특징\n",
    "   - 비지도학습법에 해당하여 타겟변수의 정의 없이 학습이 가능\n",
    "   - 분석 목적에 따라 적절한 군집으로 분석자가 정의 가능\n",
    "   - 요인분석과의 차이 : 유사한 변수를 함께 묶는 것이 아니라 각 데이터를 묶어줌\n",
    "   - 판별분석과의 차이 : 판별분석은 지도학습, 군집분석은 비지도학습\n",
    " - 거리측정방법\n",
    "   - 연속형 변수 : 유클리드거리, 표준화거리, 마할라노비스거리, 쳬비셔프 거리, 맨하탄 거리, 캔버라 거리, 민코우스키 거리 등\n",
    "   - 범주형 변수 : 자카드 거리, 코사인 거리 등\n",
    " - 계층적 군집분석\n",
    "   - n개의 군집으로 시작해 점차 군집의 개수를 줄여나가는 방법\n",
    "   - 최단연결법\n",
    "     - n*n 거리행렬에서 거리가 가장 가까운 데이터를 묶어 군집 형성\n",
    "     - 거리 계산시 최단거리를 거리로 계산하여 거리행렬 수정\n",
    "     - 수정된 거리행렬에서 거리가 가까운 데이터 또는 군집을 새로운 군집으로 형성\n",
    "   - 최장연결법 : 거리 계산시 최장거리를 거리로 계산하여 거리행렬 수정\n",
    "   - 평균연결법 : 거리 계산시 평균거리를 거리로 계산하여 거리행렬 수정\n",
    "   - 와드연결법 : 군집내 편차들의 제곱합을 고려한 방법으로 군집 간 정보의 손실을 최소화 하기 위해 군집화를 진행\n",
    " - 비계층적 군집분석\n",
    "   - n개의 개체를 g개의 군집으로 나눌 수 있는 모든 가능한 방법을 점검해 최적화한 군집을 형성하는 것\n",
    "   - k-평균 군집분석\n",
    "     - 원하는 군집의 개수와 초기값(seed)들을 정해 seed 중심으로 군집 형성  \n",
    "     -> 각 데이터를 거리가 가장 가까운 seed가 있는 군집으로 분류  \n",
    "     -> 각 군집의 seed 값을 다시 계산  \n",
    "     -> 모든 개체가 군집으로 할당될 때까지 위 과정들을 반복\n",
    "     - 장점 : 사전정보 없이 의미있는 자료구조 파악 가능, 다양한 형태의 데이터에 적용 가능, 분석방법 적용 용이\n",
    "     - 단점 : 가중치와 거리 정의 어려움, 초기 군집수를 결정하기 어려움, 사전에 주어진 목적이 없으므로 결과 해석이 어려움\n",
    " - 혼합 분포 군집\n",
    "   - 모형기반의 군집방법이며 데이터가 k개의 모수적 모형의 가중합으로 표현되는 모집단 모형으로부터 나왔다는 가정하에서 모수와 함께 가중치를 자료로 부터 추정하는 방법을 사용\n",
    "   - k개의 각 모형은 군집을 의미하며, 각 데이터는 추정된 k개의 모형 중 어느 모형으로부터 나왔을 확률이 높은 지에 따라 군집의 분류가 이루어짐\n",
    "   - 흔히 혼합모형에서의 모수와 가중치의 추정(최대가능도추정)에는 EM알고리즘이 사용\n",
    "   - 특징\n",
    "     - k-평균 군집의 절차와 유사하지만 확률분포를 도입하여 군집을 수행\n",
    "     - 군집을 몇 개의 모수로 표현할 수 있으며, 서로 다른 크기나 모양의 군집을 찾을 수 있음\n",
    "     - EM 알고리즘을 이용한 모수 추정에서 데이터가 커지면 수렴에 시간이 걸림\n",
    "     - 군집의 크기가 너무 작으면 추정의 정도가 떨어지거나 어려움\n",
    "     - k-평균 군집과 같이 이상치 자료에 민감함으로 사전에 조치가 필요\n",
    " - SOM(Self-Organizing Map) : 자기조직화지도\n",
    "   - SOM 알고리즘은 코호넨에 의해 제시, 개발되었으며 코호넨 맵이라고도 불림\n",
    "   - 비지도 신경망으로 고차원의 데이터를 이해하기 쉬운 저차원의 뉴런으로 정렬하여 지도의 형태로 형상화\n",
    "   - 이러한 형상화는 입력변수의 위치관계를 그대로 보존한다는 특징이 있음\n",
    "   - 실제 공간의 입력변수가 가까이 있으면 지도상에도 가까운 위치에 있게됨\n",
    "   - 특징\n",
    "     - 고차원의 데이터를 저차원의 지도 형태로 형상화하기 때문에 시각적으로 이해가 쉬움\n",
    "     - 입력변수의 위치관계를 그대로 보존하기 때문에 실제 데이터가 유사하면 지도상에서 가깝게 표현되며, 이런 특징 때문에 패턴 발견, 이미지 분석 등에서 뛰어난 성능을 보임\n",
    "     - 역전파 알고리즘 등을 이용하는 인공신경망과 달리 단 하나의 전방 패스를 사용함으로써 속도가 매우 빠르므로 실시간 학습처리를 할 수 있는 모형임\n",
    "\n",
    "========================================================================================================================\n",
    "\n",
    "### 5.4 연관분석\n",
    "\n",
    "#### 1. 연관분석\n",
    " - 개요\n",
    "   - 기업의 데이터베이스에서 상품의 구매, 서비스 등 일련의 거래 또는 사건들 간의 규칙을 발견하기 위한 분석\n",
    "   - 흔히 장바구니 분석, 순차분석 등이 있음\n",
    "   - 장바구니분석 : 장바구니에 무엇이 같이 들어 있는지에 대해 분석\n",
    "   - 순차분석 : 구매이력을 분석해서 A품목을 산 후 추가 B품목을 사는지를 분석\n",
    " - 형태\n",
    "   - 조건과 반응의 형태(if - then)\n",
    "   - if A then B : 만일 A가 일어나면 B가 일어난다\n",
    " - 측도\n",
    "   - 지지도 : 전체 거래 중 항목 A와 항목 B를 동시에 포함하는 거래의 비율\n",
    "     - 지지도 = P(A교B) = A,B동시에 포함된 거래수/전체 거래수\n",
    "   - 신뢰도 : 항목 A를 포함한 거래 중에서 항목 A와 항목 B가 같이 포함될 확률, 연관성의 정도를 파악 가능\n",
    "     - 신뢰도 = P(A교B)/P(A) = A,B동시에 포함된 거래수/A가 포함된 거래수\n",
    "   - 향상도 : A가 주어지지 않았을 때의 품목 B의 확률에 비해 A가 주어졌을 때의 품목 B의 확률의 증가 비율, 품목 A,B가 서로 관련이 없는 경우 향상도=1\n",
    "     - 향상도 = P(B|A)/P(B) = P(A교B)/P(A)P(B) = A,B동시에 포함된 거래수/A포함거래수xB포함거래수\n",
    " - 특징\n",
    "   - 절차 : 최소 지지도 선정(보통5%) -> 최소 지지도를 넘는 품목 분류 -> 2가지 품목집합생성 -> 반복수행으로 빈발품목 집합 선정\n",
    "   - 장점\n",
    "     - 탐색적인 기법 : 조건 반응으로 표현되는 연관성분석 결과를 쉽게 이해할 수 있음\n",
    "     - 강력한 비목적성 분석기법 : 분석 방향이나 목적이 특별히 없는 경우 목적변수가 없으므로 유용하게 활용됨\n",
    "     - 사용이 편리한 분석 데이터의 형태 : 거래 내용에 대한 데이터를 변환 없이 그 자체로 이용\n",
    "     - 계산의 용이성 : 분석을 위한 계산이 상당히 간다\n",
    "   - 단점\n",
    "     - 상당한 수의 계산과정 : 품목 수가 증가하면 분석에 필요한 계산은 기하급수적으로 늘어남\n",
    "     - 적절한 품목의 결정 : 너무 세분화한 품목을 갖고 연관성 규칙을 찾으면 수많은 연관성 규칙들이 발견됨, 하지만 의미없는 분석이 될 수도 있음\n",
    "     - 품목의 비율차이 : 사용될 모든 품목들 자체가 전체자료에서 동일한 빈도를 갖는 경우, 연관성 분석은 가장 좋은 결과를 얻음. 그러나 거래량이 적은 품목은 당연히 포함된 거래수가 적을 것이고 규칙 발견 과정 중에서 제외되기 쉬움\n",
    " - 평가기준 적용 시 주의점\n",
    "   - 두 항목의 신뢰도가 높다고 해서 꼭 두 항목이 높은 연관관계가 있는 것은 아님(지지도 함께 고려)\n",
    "     - 만약 두 항목의 신뢰도가 높게 나왔어도 전체항목 중 두 항목의 동시구매율인 지지도가 낮게 나온다면 두 항목간 연관성을 신뢰하기에는 부족\n",
    "     - 구매율 자체가 낮은 항목이기에 일반적인 상관관계로 보기엔 어려움\n",
    "   - 지지도와 신뢰도가 모두 높게 나왔더라도 꼭 두 항목이 높은 연관관계가 있는 것은 아님(항상도를 함께 고려)\n",
    "     - 일반적으로 빈번하게 구매되는 항목들에 대해서는 지지도와 신뢰도가 높게 나올 수 있음\n",
    "   - A,B 두 항목의 신뢰도가 높게 나왔을 때, 전체거래에서 B의 자체 구매율 보다 A자체 구매율이 더 높아야 의미있는 정보임\n",
    " - Apriori 알고리즘\n",
    "   - 어떤 항목집합이 빈발한다면, 그 항목집합의 모든 부분집합도 빈발\n",
    "   - 예들 들어 {우유, 빵, 과자}가 빈발 항목집합이면, 부분집합인 {우유, 빵}{우유, 과자}{빵, 과자}도 빈발항목집합 지지도의 anti-monotone 성질 : 어떤 항목집합의 지지도는 그 부분집합들의 지지도를 넘을 수 없음\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('conda3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0088ee2cbd7afdef503747ad15d8e9b92c4b3cb4dc2274aa1e35eb8b607389d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
