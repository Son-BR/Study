{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. 빅데이터 결과 해석\n",
    "\n",
    "## 01. 분석 모형 평가 및 개선\n",
    "---\n",
    "### 1.1 분석 모형 평가\n",
    "\n",
    "|-|KeyWord|\n",
    "|:--:|--|\n",
    "|평가지표|회귀 모형 평가지표, SSE, SST, SSR, R²=결정계수, R²adj, Mallow's Cp, 분류 모형 평가지표, 혼동 행렬, ROC 곡선, AUC, 이익도표|\n",
    "|분석 모형 진단|홀드 아웃 교차 검증, 다중 교차 검증, 정확도, 오차비율, 민감도, 특이도, 거짓긍정률, 정밀도, F1-score, 카파통계량|\n",
    "|교차검증|홀드 아웃 교차 검증, 랜덤 서브샘플링, K-Fold Cross Validation, LOOCV, LpOCV, RLT, 부트스트랩|\n",
    "|모수 유의성 검정|모집단평균, Z-검정, T-검정, 분산분석, 모집단분산, 카이제곱검정, F-검정|\n",
    "|적합도 검정|적합도 검정,정규성 검정, 샤피로-윌크 검정, 콜모고로프-스미르노프 검정(K-S검정), Q-Q Plot|\n",
    "\n",
    "<분석 모형 평가>\n",
    " - 모형의 유용성 판단/비교/평가 과정은 매우 중요\n",
    " - 모형을 만든 것으로 끝이 아님\n",
    "   - 객관적인 평가지표를 통해 실무에서 사용 가능한지 평가\n",
    "   - 기존 운영시스템과의 연계 / 통합을 통해 지속적인 개선\n",
    " - 분석 모형 평가란? -> 다음 사항들에 대해 분석하는 것\n",
    "   - 구축된 모형이 임의의 모형보다 더 우수한 성과를 보이는가\n",
    "   - 고려된 모형들 중 어느 것이 가장 우수한가\n",
    " - 분석 모형 평가 기준\n",
    "   - 일반화의 가능성: 데이터 확장 적용이 가능한가 -> 모집단 내 다른 데이터에서도 결과가 안정적인지 평가\n",
    "   - 효율성: 필요한 입력변수가 적을수록 효율적\n",
    "   - 예측&분류 정확성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================\n",
    "#### 1) 평가지표\n",
    "<img src=\"./Data/평가지표.png\">\n",
    "\n",
    "##### (1) 회귀 모형 평가지표\n",
    " - SSE / SST / SSR / R² = 결정계수 / R²adj / Mallow's Cp\n",
    " - 회귀 모형 평가 지표  \n",
    "<img src=\"./Data/회귀모형평가지표.png\">\n",
    "\n",
    " - 회귀 모형 기본 평가지표\n",
    "   - SSE(오차제곱합)/SST(전체제곱합)/SSR(회귀제곱합)/AE/MAE/RMSE/MAPE/MPE\n",
    "   - SSE = 오차제곱합 = 예측값과 실젯값의 차이(오차) 제곱 합\n",
    "   - SST = 전체제곱합 = 실젯값과 평균값의 차이 제곱 합\n",
    "   - SSR = 회귀제곱합 = 예측값과 평균값의 차이 제곱 합\n",
    "   - AE = Average Error = 평균 오차\n",
    "   - MAE = Mean Absolute Error = 평균 절대 오차\n",
    "   - RMSE = Root Mean Squared Error = 평균 제곱근 오차\n",
    "   - MAPE = Mean Absolute Percentage Error = 평균 절대 백분율 오차\n",
    "   - MPE = Mean Percentage Error = 평균 백분율 오차  \n",
    "   <br>\n",
    " - 회귀 모형 성능 검증지표\n",
    "   - R²(결정계수) / R²adj(수정된 결정계수) / Mallow's Cp\n",
    "   - 결정계수\n",
    "     - 회귀모형이 실제값을 얼마나 잘 나타내는지에 대한 비율(0~1)\n",
    "     - 독립변수 개수가 많은 모형의 경우 부적합\n",
    "     - 단점: 모형의 변수 개수가 증가할 때, 그 변수가 유의하지 않더라도 결정계수는 증가\n",
    "   - 수정된 결정계수\n",
    "     - 결정계수의 단점을 보완함 -> 수정된 결정계수는 결정계수보다 항상 작음\n",
    "     - 유의하지 않은 독립변수를 추가할수록, 패널티 부과 -> 감소\n",
    "     - 모형이 유용한 독립변수를 추가할수록 증가\n",
    "     - 따라서, 독립변수 개수가 많은 모형에 적합\n",
    "   - Mallow's Cp\n",
    "     - 적절하지 않은 독립변수 추가에 대한 패널티를 부과한 통계량\n",
    "     - 값이 작을수록, 실제값을 잘 설명하는 모형임\n",
    "\n",
    "##### (2) 분류 모형 평가지표\n",
    " - 혼동 행렬 / ROC 곡선 / AUC / 이익도표\n",
    " - 혼동 행렬(Confusion Matrix)(정오 행렬)  \n",
    " <img src=\"./Data/혼동행렬.png\">\n",
    " \n",
    "   - 모델이 분류한 예측범주와 실제 분류범주를 교차표로 정리한 행렬(N⨉N)\n",
    "   - 예측값과 실제값의 일치빈도를 통해 모델 정확도 평가\n",
    "   - 모델 성능을 평가할 수 있는 평가지표 도출  \n",
    "   -> 정확도/오차비율/민감도/특이도/거짓긍정렬/정밀도/F1-score/카파통계량  \n",
    "   \n",
    "   <img src=\"./Data/혼동행렬이용한평가지표.png\">\n",
    "<br>\n",
    "\n",
    " - ROC 곡선(ROC Curve)  \n",
    " <img src=\"./Data/ROC Curve.png\">\n",
    "\n",
    " - 이익 도표(Gain Chart)\n",
    "   - 그래프를 통해 분류모형의 성능을 평가함(이익 도표 = 이익 곡선 = 리프트 곡선)\n",
    "   - 이익(Gain)\n",
    "     - 목표범주에 속한 개체들이 임의로 나눈 등급별로 얼마나 분포하고 있는지 나타내는 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================\n",
    "#### 2) 분석 모형 진단\n",
    "##### (1) 데이터 분석 모형의 오류\n",
    " - 일반화 오류 / 학습 오류\n",
    " - 일반화 오류(Generalization Error): 주어진 데이터의 특성을 지나치게 반영 -> 주변특성&단순잡음 묘사 -> 과대 적합\n",
    " - 학습 오류(Training Error): 주어진 데이터의 특성을 덜 반영하도록 모형 생성 -> 과소 적합\n",
    "\n",
    "##### (2) 데이터 분석 모형 검증\n",
    " - 홀드 아웃 교차 검증 / 다중 교차 검증\n",
    " - 홀드 아웃 교차 검증\n",
    "   - 데이터 집합 구분: 서로 겹치지 않는 학습집합, 시험집합으로 무작위 구분\n",
    "   - 학습집합으로 분석모형을 구축\n",
    "   - 시험집합으로 분석모형의 성능 평가\n",
    " - 다중 교차 검증\n",
    "   - 데이터 집합 나눔: 같은 크기의 부분집합 k개로 무작위 나눔\n",
    "   - k개 부분집합 = 1개는 시험집합 + (k-1)개는 학습집합\n",
    "   - 종류: Random Sub-Sampling/K-Fold Cross Validation/Leave-One-Out Cross Validation/Bootstrap\n",
    "\n",
    "##### (3) 분석 모형 시각화\n",
    " - 정보 구조화 -> 정보 시각화 -> 정보 시각표현\n",
    " - 시각화: 그래프/그림과 같은 시각적 도구를 통해 의사결정자에게 제공하여, 분석결과를 쉽게 이해할 수 있게 함\n",
    " - 정보 구조화: 데이터 수집 및 탐색/데이터 분류/데이터 배열/데이터 재배열\n",
    " - 정보 시각화: 시각/분포/관계/비교/공간 시각화\n",
    " - 정보 시각표현: 그래픽 7요소/그래픽디자인 기본원리/인터랙션(Interaction)/시각정보디자인 7원칙\n",
    "\n",
    "##### (4) 분석 모형 진단\n",
    " - 기본 가정 진단 / 잔차의 산점도\n",
    " - 선정한 분석모형의 기본가정에 대한 진단이 필요\n",
    " - 회귀모형은 잔차의 산점도를 이용하여 모형 진단\n",
    " - 선형성 / 독립성 / 등분산성 / 정상성(정규성)\n",
    "   - 선형성: 잔차의 산점도\n",
    "   - 독립성: 잔차의 산점도 - 경향성 없이 일정한 분포인가?\n",
    "   - 등분산성: 잔차의 산점도 - 전체적으로 고르게 흩어져있는가?\n",
    "   - 정상성(정규성): 샤피로-윌크 검정 / 콜모고로프-스미르노프 검정 / Q-Q Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================\n",
    "#### 3) 교차 검증\n",
    "##### (1) 교차 검증(Cross Validation)\n",
    " - 모델의 일반화 오차에 대해 신뢰할만한 추정치를 구하기 위하여 훈련&평가 데이터를 기반한 검증 기법\n",
    " - 홀드 아웃 교차 검증, 랜덤 서브샘플링, K-Fold Cross Validation, LOOCV, 부트스트랩\n",
    "\n",
    "<img src=\"./Data/교차검증비교.png\">\n",
    "\n",
    "##### (2) 홀드 아웃 교차 검증(Holdout Cross Validation)\n",
    " - 비복원추출로 랜덤하게 학습/평가 데이터를 나누어 검증\n",
    " - 데이터를 나누는 방법에 따라 결과가 많이 달라짐(5:5, 3:7, 2:1)\n",
    "   - 학습 데이터(Training set): 분류기 만들 때 사용\n",
    "   - 검증 데이터(Validation set): 분류기들의 매개변수 최적화를 위해 사용\n",
    "   - 평가 데이터(Test set): 최적화된 분류기 성능 평가를 위해 사용\n",
    " - 데이터 손실O : 평가 데이터는 학습에 사용할 수 없음\n",
    " - 계산량↓ 평가 쉬움↑\n",
    "\n",
    "##### (3) 랜덤 서브샘플링(Random Sub-Sampling)\n",
    " - 모집단에서 표본을 무작위 추출\n",
    " - 홀드아웃 반복 -> 데이터 손실X\n",
    "- 측정/평가 비용 가장 적음\n",
    " - 각 샘플들을 학습/평가에 얼마나 사용할지 횟수 제한X -> 특정 데이터만 학습할 수 있음\n",
    "\n",
    "##### (4) K-Fold Cross Validation\n",
    " - 무작위/동일크기/K개 부분집합으로 나눔 -> 실험결과 K개를 종합\n",
    " - 데이터 분할\n",
    "   - 전체 집합 = K 개\n",
    "   - 학습 집합 = K-1 개\n",
    "   - 평가 집합 = 1 개\n",
    " - 모든 데이터를 학습/평가에 사용 가능\n",
    " - K값에 따라 달라짐\n",
    "   - K값 증가할수록, 계산량도 증가함\n",
    "   - K = 10 이면, 데이터 10% 낭비됨\n",
    " - LOOCV 보다 측정/평가 비용 적음\n",
    " - 절차: 동등분할 -> 학습/평가데이터 구성 -> 분류기 학습 -> 분류기 성능확인\n",
    "   - 학습/평가데이터 구성: (K-1)개 부분집합은 학습, 1개 부분집합은 평가에 쓰는 K개의 실험데이터 구성\n",
    "   - 분류기 성능확인: 실험 결과 K개를 종합하여 분류기의 최종 성능을 확인\n",
    "\n",
    "##### (5) LOOCV(Leave-One-Out Cross Validation)\n",
    " - 전체 데이터 N개 중 샘플 1개만 평가 / (N-1)개는 학습 -> N번 반복\n",
    " - 데이터 분할\n",
    "   - 전체 데이터 = N 개\n",
    "   - 학습 데이터 = N-1 개\n",
    "   - 평가 데이터 = 1 개\n",
    " - 데이터 손실X\n",
    " - 계산량 많음 -> 측정/평가 비용 가장 비쌈\n",
    " - 작은 크기 데이터에 좋음\n",
    " - 방법은 K-Fold랑 같음 -> K-Fold는 부분집합 개수 K / LOOCV는 데이터 개수 N\n",
    "\n",
    "##### (6) LpOCV(Leave-p-Out Cross Validation)\n",
    " - 전체 데이터 N개 중 샘플 p개만 평가 / (N-p)개는 학습 -> nCp번 반복\n",
    " - 데이터 분할\n",
    "   - 전체 데이터 = N 개\n",
    "   - 학습 데이터 = N-p 개\n",
    "   - 평가 데이터 = p 개\n",
    " - 계산량/시간 부담 큼\n",
    "\n",
    "##### (7) RLT(Repeated Learning-Testing)\n",
    " - 랜덤 비복원추출\n",
    " - 절차: 데이터 분리 -> 훈련 -> 에러 계산 -> 반복 -> 평균오류율 계산\n",
    "   - 데이터 분리: 랜덤하게 학습/검증 데이터 분리\n",
    "   - 데이터 훈련: 학습 데이터로만 훈련\n",
    "   - 에러 계산: 검증 데이터로 Error 계산\n",
    "   - 반복: 데이터 훈련과 에러 계산을 2회 더 반복\n",
    "   - 평균 오류율 E = ∑E / N\n",
    "\n",
    "##### (8) 부트스트랩(Bootstrap)\n",
    " - 단순랜덤 복원추출 -> 동일크기 표본 여러개 샘플링\n",
    " - 랜덤 복원추출 -> 중복 허용 -> 특정 샘플이 학습 데이터에 포함될 확률 = 약 63.2%\n",
    " - 학습 데이터에 한번도 포함되지 않는 데이터 발생 -> 평가에 사용함 = 약 36.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================\n",
    "#### 4) 모수 유의성 검정\n",
    "<가설검정 유형>\n",
    "<img src=\"./Data/가설검정유형.png\">\n",
    "\n",
    "##### (1) 모집단과 모수 관계\n",
    " - 모집단(Population): 분석/관심 대상 전체 그룹\n",
    " - 모수(Parameter): 모집단을 설명하는 어떤 값/ 모집단의 특성을 나타내는 값\n",
    " - 표본(Sample): 모집단 일부/ 모집단 분석을 위해 추출한 한 집단의 관측치\n",
    " - 통계량(Statistic): 모집단을 설명하는 어떤 값을 표본으로부터 구한 값/표본의 특성을 나타내는 값\n",
    "\n",
    "##### (2) 모집단 평균에 대한 유의성 검정\n",
    " - Z-검정 / T-검정 / 분산분석\n",
    "<img src=\"./Data/모집단평균유의성검정.png\">\n",
    "\n",
    " - T-분포: 표준정규분포와 유사\n",
    "   - 0 중심 좌우대칭 but 꼬리가 더 길고 평평함\n",
    "   - 정규분포의 평균을 측정할 때 많이 사용하는 분포\n",
    "   - 적은 표본으로 모집단 평균을 추정하기 위해, 정규분포 대신 사용하는 확률분포\n",
    "   - 자유도(= 표본개수-1) 증가할수록, 표준정규분포에 가까워짐\n",
    "   - 중심극한정리: 표본개수가 충분히 크다면/자유도가 30이 넘으면, 정규분포에 가까워짐\n",
    "\n",
    "##### (3) 모집단 분산에 대한 유의성 검정\n",
    " - 카이제곱검정 / F-검정\n",
    "<img src=\"./Data/모집단분산유의성검정.png\">\n",
    "\n",
    " - 카이제곱분포:  χ = Z₁² + Z₂² + Z₃² + ... + Zn²\n",
    "   - 각각 독립인 표준정규분포를 취하는 확률변수 Z의 제곱의 합인 χ 를 따르는 확률 분포\n",
    "   - 자유도 n 이 작을수록, 왼쪽으로 치우침\n",
    "   - 자유도 n이 클수록, 정규분포에 가까워짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================\n",
    "#### 5) 적합도 검정\n",
    "##### (1) 적합도 검정\n",
    " - 표본집단 분포가 특정이론을 따르고 있는지 검정\n",
    " - 기법 유형: 가정된 확률이 정해진 경우 & 아닌경우\n",
    "   - 가정된 확률 검정: 카이제곱검정\n",
    "   - 가정된 확률 없음 -> 정규성 검정: 샤피로-윌크 검정/콜모고로프-스미르노프 검정/Q-Q Plot\n",
    "\n",
    "##### (2) 적합도 검정 기법\n",
    " - chisq.test() -> p-value>0.05 -> 관측된 데이터가 가정된 확률을 따르\n",
    " - 정규성 검정: 정규성 가정을 만족하지 못한다면, 모형 타당성이 떨어지고 신뢰성을 의심받을 수 있음 -> 검정 필요\n",
    "\n",
    "<img src=\"./Data/적합도검정기법.png\">\n",
    "\n",
    " - Q-Q Plot  \n",
    "<img src=\"./Data/qqplot.png\" width=\"350\" height=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2 분석 모형 개선\n",
    "\n",
    "|-|KeyWord|\n",
    "|:--:|--|\n",
    "|과대적합방지|데이터증강, 모델복잡도감소, 가중치규제, L1규제, L2규제, 드롭아웃|\n",
    "|매개변수 최적화|확률적 경사 하강법, 모멘텀, AdaGrad, Adam|\n",
    "|분석 모형 융합|취합방법론, 다수결, 배깅, 페이스팅, 랜덤서브스페이스, 랜덤패치, 랜덤포레스트, 부스팅방법론, 에이다부스트, 그래디언트부스트|\n",
    "\n",
    "============================================================\n",
    "#### 1) 과대 적합 방지\n",
    "##### (1) 과대 적합(Over-fitting)\n",
    " - 지나친 학습 -> 일반화↓\n",
    " - 제한된 학습데이터셋에 지나치게 특화되어 새로운 데이터에 대한 오차가 매우 커지는 현상\n",
    " - 과대 적합이 발생하는 경우: 모델 파라미터 개수 많음 / 학습데이터셋 부족\n",
    " - 일반화(Generalization): 테스트데이터에 대해 높은 성능을 갖춤/정상추정함/과소&과대적합X\n",
    "   - 과소 적합: 지나치게 단순한 모델/데이터에 내재된 구조를 학습하지 못함\n",
    "   - 과대 적합: 지나치게 학습데이터에 적합/ 일반화 떨어짐\n",
    "\n",
    "##### (2) 과대 적합 방지\n",
    " - 데이터 증강 / 모델 복잡도 감소 / 가중치 규제 / 드롭아웃\n",
    " - 데이터 증강(Data Augmentation)\n",
    "   - 데이터 양이 적을 경우, 데이터를 변형하여 양을 늘림 \n",
    " - 모델 복잡도 감소\n",
    "   - 은닉층 개수 감소 / 모델 수용력 낮춤 -> 모델 복잡도 줄일 수 있음\n",
    " - 가중치 규제 적용\n",
    "   - 개별 가중치 값을 제한 -> 복잡한 모델을 간단하게\n",
    "   - 비용함수(Cost Function): 관측값과 연산값의 차이를 도출  \n",
    "   -> 비용함수 최소화를 위해서, 가중치들이 작아져야 함\n",
    "   - λ = 규제 강도를 정하는 하이퍼 파라미터  \n",
    "   ->  λ 값이 크면, 가중치 규제를 위해 추가한 항들을 작게 유지하는 것을 우선함\n",
    "   - L1 규제: 모든 가중치들의 절댓값 합계를 비용함수에 추가 -> λ|w|\n",
    "   - L2 규제: 모든 가중치들의 제곱합을 비용함수에 추가 -> (1/2)λw²\n",
    " - 드롭아웃(Dropout)\n",
    "   - 학습 과정에서 신경망 일부를 사용하지 않음\n",
    "   - 특정 뉴런/조합에 너무 의존적인 인공신경망이 되는 것을 방지\n",
    "   - 매번 랜덤으로 뉴런 선택 -> 서로 다른 신경망들을 앙상블하는 것과 같은 효과\n",
    "   - 신경망 학습 과정에서만 사용하는 기법\n",
    "   - 예측 과정에서는 드롭아웃을 사용하지 않음\n",
    "   - 드롭아웃 유형: 초기(DNN) / 공간적(CNN) / 시간적(RNN) 드롭아웃\n",
    "     - 초기 드롭아웃: DNN 에서 사용\n",
    "       - p의 확률로 노드들을 생략하여 학습함\n",
    "       - 일반적으로 p = 0.5\n",
    "     - 공간적 드롭아웃: CNN 에서 사용\n",
    "       - 피처맵 내 노드 전체에 대해 드롭아웃 적용 여부를 결정함 \n",
    "     - 시간적 드롭아웃: RNN 에서 사용\n",
    "       - 노드가 아닌, 연결선 일부를 생략하여 학습함(Drop Connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================\n",
    "#### 2) 매개변수 최적화\n",
    "##### (1) 매개변수(Parameter)\n",
    " - 데이터 학습을 통해, 모델 내부에서 결정되는 변수\n",
    "\n",
    "##### (2) 매개변수 최적화(Parameter Optimization)\n",
    " - 손실함수(Loss Function): 학습모델의 출력값과 레이블 실제값의 차이(오차)\n",
    " - 모델 학습의 목적 = 매개변수 최적화\n",
    "   - 손실함수의 값을 최소화하는 매개변수를 찾는 것\n",
    "   - 오차를 최소화하는 가중치와 편향을 찾는 것\n",
    "\n",
    "##### (3) 매개변수 종류: 가중치 & 편향\n",
    " - 가중치(Weight): \"곱\"\n",
    "   - 입력값마다 각기 다르게 곱해지는 수치\n",
    "   - y = ax+b 에서 기울기 a 해당\n",
    " - 편향(Bias): \"합\"\n",
    "   - 가중합에 더해주는 상수\n",
    "   - y = ax+b 에서 절편 b 에 해당\n",
    "\n",
    "##### (4) 매개변수 최적화 기법\n",
    " - 확률적 경사 하강법 / 모멘텀 / AdaGrad / Adam\n",
    " - 2차원 손실함수 그래프를 이용하여 매개변수 최적화를 수행\n",
    "   - X축 = 가중치(Wi)\n",
    "   - Y축 = 손실값(=오차)\n",
    "   - 그래프에서 기울기가 0인 지점(= 손실값이 최소화되는 지점)에서 최적의 매개변수를 찾을 수 있음\n",
    " - 매개변수 최적화 과정은 학습률에 따라서 달라짐\n",
    "   - 학습률 적음 -> 매우 느린 학습 -> 최적화에 많은 시간 소요\n",
    "   - 학습률 높음 -> 기울기=0 지점을 지나침 -> 최적화 실패\n",
    "   - 학습률 적당 -> 기울기=0 지점 찾음 -> 최적화 성공\n",
    "\n",
    "<img src=\"./Data/매개변수최적화.png\">\n",
    "\n",
    " - 확률적 경사 하강법(SGD): 기울기를 구할 때 1개의 데이터를 무작위로 선택함(확률적)\n",
    "   - 문제점: 지역극소점에 갇히는 문제 자주 발생\n",
    "     - 손실함수 그래프에서 지역극소점(Local)에 갇혀서, 전역극소점(Global)을 찾지 못하는 경우가 많음\n",
    "     - 손실함수가 방향에 따라 기울기가 달라지는 비등방성 함수일 경우 매우 비효율적\n",
    "   - SGD의 단점 개선을 위해 고안된 방법론들이 모멘텀/AdaGrad/Adam\n",
    "   - 탐색경로: 지그재그로 크게 변함<br><br>\n",
    " - 모멘텀(Momentum): SGD + 속도\n",
    "   - 기울기가 줄어도 누적된 기울기 값에 의해 탐색경로의 변위가 줄어들어서 빠르게 최적점으로 수렴\n",
    "   - X축의 한 방향으로 일정한 가속 / Y축 방향 속도는 일정하지 않음\n",
    "   - 관성의 방향을 고려하여, 진동과 폭을 줄이는 효과\n",
    "   - 모멘텀 갱신경로: 공이 그릇 바닥을 구르듯 움직임 -> SGD보다 지그재그 덜함<br><br>\n",
    " - AdaGrad(Adaptive Gradient Algorithm): 학습 진행할수록 학습률 감소시킴\n",
    "   - 학습률 감소 기법 적용\n",
    "     - 손실함수 처음 부분: 기울기 큼 -> 학습률 큼\n",
    "     - 최적점에 가까워짐: 기울기 감소 -> 학습률 줄여서 조금씩 작게 학습\n",
    "   - 최적점 탐색경로\n",
    "     - 손실함수 처음 부분: y축 방향으로 기울기 큼 -> 큰 폭으로 움직임\n",
    "     - 최적점에 가까워짐: y축 방향으로 갱신 강도 빠르게 감소 -> 큰 폭으로 작아짐\n",
    "   - 각각의 매개변수에 맞는 학습률 값을 만들어줌\n",
    "   - 탐색경로: 지그재그 움직임이 빠르게 줄어듦<br><br>\n",
    " - Adam(Adaptive Moment Estimation): 모멘텀 + AdaGrad\n",
    "   - Adam 갱신경로\n",
    "     - 모멘텀처럼 공이 그릇 바닥을 구르듯 움직임\n",
    "     - 모멘텀보다 좌우 흔들림 적음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================\n",
    "#### 3) 분석 모형 융함\n",
    "##### (1) 취합 방법론(Aggregation)\n",
    " - 다수결/배깅/페이스팅/랜덤 서브스페이스/랜덤 패치/랜덤 포레스트\n",
    "\n",
    "<img src=\"./Data/취합방법론.png\">\n",
    "\n",
    "##### (2) 부스팅 방법론(Boosting)\n",
    " - 에이다 / 그래디언트 부스트\n",
    " - 에이다 부스트(AdaBoost) = 적응 부스트(Adaptive Boost)\n",
    "   - 약한 모형 각각을 순차적으로 적용하는 과정에서 잘 분류된 샘플 가중치 낮추고 오분류된 샘플 가중치 높여서 샘플 분포를 변화시키는 기법\n",
    " - 그레디언트 부스트(Gradient Boost)\n",
    "   - 약한 모형 각각을 순차적으로 적용하는 과정에서 오분류된 샘플 에러를 최적화하는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================\n",
    "#### 4) 최종 모형 선정\n",
    "##### (1) 최종 모형 선정 절차\n",
    " - 최종 모형 평가 기준 선정 -> 최종 모형 분석 결과 검토 -> 알고리즘별로 결과 비교\n",
    " - 평가 기준 선정: 정확도 / 재현율 / 정밀도 등의 평가지표 이용\n",
    " - 분석 결과 검토: 평가 기준, 실질적인 활용 가능성에 대한 검토\n",
    " - 알고리즘별 결과 비교: 알고리즘별로 파라미터를 변경하며 수행 -> 변경 전후의 차이점 비교, 결과 기록"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('conda3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0088ee2cbd7afdef503747ad15d8e9b92c4b3cb4dc2274aa1e35eb8b607389d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
